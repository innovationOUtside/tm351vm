2018-04-30T18:35:36.619+0000 I CONTROL  [initandlisten] MongoDB starting : pid=5116 port=47017 dbpath=/data/shard1/rs0 64-bit host=tm351-18J-test-student
2018-04-30T18:35:36.619+0000 I CONTROL  [initandlisten] db version v3.6.4
2018-04-30T18:35:36.619+0000 I CONTROL  [initandlisten] git version: d0181a711f7e7f39e60b5aeb1dc7097bf6ae5856
2018-04-30T18:35:36.619+0000 I CONTROL  [initandlisten] OpenSSL version: OpenSSL 1.0.2g  1 Mar 2016
2018-04-30T18:35:36.619+0000 I CONTROL  [initandlisten] allocator: tcmalloc
2018-04-30T18:35:36.619+0000 I CONTROL  [initandlisten] modules: none
2018-04-30T18:35:36.620+0000 I CONTROL  [initandlisten] build environment:
2018-04-30T18:35:36.620+0000 I CONTROL  [initandlisten]     distmod: ubuntu1604
2018-04-30T18:35:36.620+0000 I CONTROL  [initandlisten]     distarch: x86_64
2018-04-30T18:35:36.620+0000 I CONTROL  [initandlisten]     target_arch: x86_64
2018-04-30T18:35:36.620+0000 I CONTROL  [initandlisten] options: { net: { port: 47017 }, processManagement: { fork: true, pidFilePath: "/vagrant/logs/mongocluster_s1-r0.pid" }, replication: { replSet: "s1" }, sharding: { clusterRole: "shardsvr" }, storage: { dbPath: "/data/shard1/rs0", mmapv1: { smallFiles: true } }, systemLog: { destination: "file", path: "/vagrant/logs/mongocluster_s1-r0.log" } }
2018-04-30T18:35:36.620+0000 I STORAGE  [initandlisten] 
2018-04-30T18:35:36.620+0000 I STORAGE  [initandlisten] ** WARNING: Using the XFS filesystem is strongly recommended with the WiredTiger storage engine
2018-04-30T18:35:36.620+0000 I STORAGE  [initandlisten] **          See http://dochub.mongodb.org/core/prodnotes-filesystem
2018-04-30T18:35:36.620+0000 I STORAGE  [initandlisten] wiredtiger_open config: create,cache_size=256M,session_max=20000,eviction=(threads_min=4,threads_max=4),config_base=false,statistics=(fast),cache_cursors=false,log=(enabled=true,archive=true,path=journal,compressor=snappy),file_manager=(close_idle_time=100000),statistics_log=(wait=0),verbose=(recovery_progress),
2018-04-30T18:35:37.180+0000 I STORAGE  [initandlisten] WiredTiger message [1525113337:180371][5116:0x7fc0de8f89c0], txn-recover: Set global recovery timestamp: 0
2018-04-30T18:35:37.194+0000 W STORAGE  [initandlisten] Detected configuration for non-active storage engine mmapv1 when current storage engine is wiredTiger
2018-04-30T18:35:37.194+0000 I CONTROL  [initandlisten] 
2018-04-30T18:35:37.194+0000 I CONTROL  [initandlisten] ** WARNING: Access control is not enabled for the database.
2018-04-30T18:35:37.194+0000 I CONTROL  [initandlisten] **          Read and write access to data and configuration is unrestricted.
2018-04-30T18:35:37.194+0000 I CONTROL  [initandlisten] ** WARNING: You are running this process as the root user, which is not recommended.
2018-04-30T18:35:37.194+0000 I CONTROL  [initandlisten] 
2018-04-30T18:35:37.194+0000 I CONTROL  [initandlisten] ** WARNING: This server is bound to localhost.
2018-04-30T18:35:37.194+0000 I CONTROL  [initandlisten] **          Remote systems will be unable to connect to this server. 
2018-04-30T18:35:37.194+0000 I CONTROL  [initandlisten] **          Start the server with --bind_ip <address> to specify which IP 
2018-04-30T18:35:37.194+0000 I CONTROL  [initandlisten] **          addresses it should serve responses from, or with --bind_ip_all to
2018-04-30T18:35:37.195+0000 I CONTROL  [initandlisten] **          bind to all interfaces. If this behavior is desired, start the
2018-04-30T18:35:37.195+0000 I CONTROL  [initandlisten] **          server with --bind_ip 127.0.0.1 to disable this warning.
2018-04-30T18:35:37.195+0000 I CONTROL  [initandlisten] 
2018-04-30T18:35:37.195+0000 I CONTROL  [initandlisten] 
2018-04-30T18:35:37.195+0000 I CONTROL  [initandlisten] ** WARNING: /sys/kernel/mm/transparent_hugepage/enabled is 'always'.
2018-04-30T18:35:37.195+0000 I CONTROL  [initandlisten] **        We suggest setting it to 'never'
2018-04-30T18:35:37.195+0000 I CONTROL  [initandlisten] 
2018-04-30T18:35:37.195+0000 I CONTROL  [initandlisten] ** WARNING: /sys/kernel/mm/transparent_hugepage/defrag is 'always'.
2018-04-30T18:35:37.195+0000 I CONTROL  [initandlisten] **        We suggest setting it to 'never'
2018-04-30T18:35:37.195+0000 I CONTROL  [initandlisten] 
2018-04-30T18:35:37.197+0000 W SHARDING [initandlisten] Started with --shardsvr, but no shardIdentity document was found on disk in admin.system.version. This most likely means this server has not yet been added to a sharded cluster.
2018-04-30T18:35:37.197+0000 I STORAGE  [initandlisten] createCollection: local.startup_log with no UUID.
2018-04-30T18:35:37.204+0000 I FTDC     [initandlisten] Initializing full-time diagnostic data capture with directory '/data/shard1/rs0/diagnostic.data'
2018-04-30T18:35:37.204+0000 I STORAGE  [initandlisten] createCollection: local.me with no UUID.
2018-04-30T18:35:37.210+0000 I STORAGE  [initandlisten] createCollection: local.replset.minvalid with no UUID.
2018-04-30T18:35:37.216+0000 I REPL     [initandlisten] Did not find local voted for document at startup.
2018-04-30T18:35:37.217+0000 I REPL     [initandlisten] Did not find local Rollback ID document at startup. Creating one.
2018-04-30T18:35:37.217+0000 I STORAGE  [initandlisten] createCollection: local.system.rollback.id with no UUID.
2018-04-30T18:35:37.222+0000 I REPL     [initandlisten] Initialized the rollback ID to 1
2018-04-30T18:35:37.222+0000 I REPL     [initandlisten] Did not find local replica set configuration document at startup;  NoMatchingDocument: Did not find replica set configuration document in local.system.replset
2018-04-30T18:35:37.222+0000 I NETWORK  [initandlisten] waiting for connections on port 47017
2018-04-30T18:35:42.266+0000 I NETWORK  [listener] connection accepted from 127.0.0.1:55046 #1 (1 connection now open)
2018-04-30T18:35:42.267+0000 I NETWORK  [conn1] received client metadata from 127.0.0.1:55046 conn1: { application: { name: "MongoDB Shell" }, driver: { name: "MongoDB Internal Client", version: "3.6.4" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2018-04-30T18:35:42.270+0000 I REPL     [conn1] replSetInitiate admin command received from client
2018-04-30T18:35:42.270+0000 I REPL     [conn1] replSetInitiate config object with 1 members parses ok
2018-04-30T18:35:42.270+0000 I REPL     [conn1] ******
2018-04-30T18:35:42.270+0000 I REPL     [conn1] creating replication oplog of size: 2734MB...
2018-04-30T18:35:42.271+0000 I STORAGE  [conn1] createCollection: local.oplog.rs with no UUID.
2018-04-30T18:35:42.276+0000 I STORAGE  [conn1] Starting WiredTigerRecordStoreThread local.oplog.rs
2018-04-30T18:35:42.276+0000 I STORAGE  [conn1] The size storer reports that the oplog contains 0 records totaling to 0 bytes
2018-04-30T18:35:42.276+0000 I STORAGE  [conn1] Scanning the oplog to determine where to place markers for truncation
2018-04-30T18:35:42.292+0000 I REPL     [conn1] ******
2018-04-30T18:35:42.292+0000 I STORAGE  [conn1] createCollection: local.system.replset with no UUID.
2018-04-30T18:35:42.299+0000 I STORAGE  [conn1] createCollection: admin.system.version with no UUID.
2018-04-30T18:35:42.305+0000 I REPL     [conn1] New replica set config in use: { _id: "s1", version: 1, protocolVersion: 1, members: [ { _id: 0, host: "localhost:47017", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 } ], settings: { chainingAllowed: true, heartbeatIntervalMillis: 2000, heartbeatTimeoutSecs: 10, electionTimeoutMillis: 10000, catchUpTimeoutMillis: -1, catchUpTakeoverDelayMillis: 30000, getLastErrorModes: {}, getLastErrorDefaults: { w: 1, wtimeout: 0 }, replicaSetId: ObjectId('5ae761feb3f9f8ea6914d63b') } }
2018-04-30T18:35:42.306+0000 I REPL     [conn1] This node is localhost:47017 in the config
2018-04-30T18:35:42.306+0000 I REPL     [conn1] transition to STARTUP2 from STARTUP
2018-04-30T18:35:42.306+0000 I REPL     [conn1] Starting replication storage threads
2018-04-30T18:35:42.306+0000 I REPL     [conn1] transition to RECOVERING from STARTUP2
2018-04-30T18:35:42.306+0000 I REPL     [conn1] Starting replication fetcher thread
2018-04-30T18:35:42.306+0000 I REPL     [conn1] Starting replication applier thread
2018-04-30T18:35:42.307+0000 I REPL     [conn1] Starting replication reporter thread
2018-04-30T18:35:42.310+0000 I NETWORK  [conn1] end connection 127.0.0.1:55046 (0 connections now open)
2018-04-30T18:35:42.315+0000 I REPL     [rsSync] transition to SECONDARY from RECOVERING
2018-04-30T18:35:42.315+0000 I REPL     [rsSync] conducting a dry run election to see if we could be elected. current term: 0
2018-04-30T18:35:42.315+0000 I REPL     [replexec-0] dry election run succeeded, running for election in term 1
2018-04-30T18:35:42.315+0000 I STORAGE  [replexec-0] createCollection: local.replset.election with no UUID.
2018-04-30T18:35:42.323+0000 I REPL     [replexec-0] election succeeded, assuming primary role in term 1
2018-04-30T18:35:42.324+0000 I REPL     [replexec-0] transition to PRIMARY from SECONDARY
2018-04-30T18:35:42.328+0000 I REPL     [replexec-0] Entering primary catch-up mode.
2018-04-30T18:35:42.328+0000 I REPL     [replexec-0] Exited primary catch-up mode.
2018-04-30T18:35:44.317+0000 I STORAGE  [rsSync] createCollection: config.transactions with no UUID.
2018-04-30T18:35:44.328+0000 I REPL     [rsSync] transition to primary complete; database writes are now permitted
2018-04-30T18:35:58.147+0000 I NETWORK  [listener] connection accepted from 127.0.0.1:55074 #2 (1 connection now open)
2018-04-30T18:35:58.148+0000 I NETWORK  [conn2] received client metadata from 127.0.0.1:55074 conn2: { driver: { name: "MongoDB Internal Client", version: "3.6.4" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2018-04-30T18:35:58.149+0000 I NETWORK  [listener] connection accepted from 127.0.0.1:55078 #3 (2 connections now open)
2018-04-30T18:35:58.149+0000 I NETWORK  [conn3] received client metadata from 127.0.0.1:55078 conn3: { driver: { name: "AddShard-TaskExecutor", version: "3.6.4" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2018-04-30T18:35:58.150+0000 I COMMAND  [conn3] CMD: drop config.system.sessions
2018-04-30T18:35:58.151+0000 I SHARDING [conn3] initializing sharding state with: { _id: "shardIdentity", configsvrConnectionString: "c1/localhost:57050", shardName: "s1", clusterId: ObjectId('5ae761e81b1b0bfabb4ae653') }
2018-04-30T18:35:58.151+0000 I SHARDING [conn3] first cluster operation detected, adding sharding hook to enable versioning and authentication to remote servers
2018-04-30T18:35:58.152+0000 I NETWORK  [conn3] Starting new replica set monitor for c1/localhost:57050
2018-04-30T18:35:58.153+0000 I SHARDING [conn3] initialized sharding components for primary node.
2018-04-30T18:35:58.153+0000 I COMMAND  [conn3] setting featureCompatibilityVersion to upgrading to 3.6
2018-04-30T18:35:58.154+0000 I NETWORK  [conn3] Skip closing connection for connection # 3
2018-04-30T18:35:58.154+0000 I NETWORK  [conn3] Skip closing connection for connection # 2
2018-04-30T18:35:58.154+0000 I SHARDING [thread4] creating distributed lock ping thread for process tm351-18J-test-student:47017:1525113358:5111203876141935344 (sleeping for 30000ms)
2018-04-30T18:35:58.155+0000 I COMMAND  [conn3] obtaining UUIDs for pre-existing sharded collections from config server
2018-04-30T18:35:58.155+0000 I NETWORK  [ReplicaSetMonitor-TaskExecutor-0] Successfully connected to localhost:57050 (1 connections now open to localhost:57050 with a 5 second timeout)
2018-04-30T18:35:58.155+0000 I ASIO     [NetworkInterfaceASIO-ShardRegistry-0] Connecting to localhost:57050
2018-04-30T18:35:58.155+0000 I ASIO     [NetworkInterfaceASIO-ShardRegistry-0] Connecting to localhost:57050
2018-04-30T18:35:58.156+0000 I ASIO     [NetworkInterfaceASIO-ShardRegistry-0] Successfully connected to localhost:57050, took 1ms (2 connections now open to localhost:57050)
2018-04-30T18:35:58.157+0000 I ASIO     [NetworkInterfaceASIO-ShardRegistry-0] Connecting to localhost:57050
2018-04-30T18:35:58.158+0000 W SHARDING [replSetDistLockPinger] pinging failed for distributed lock pinger :: caused by :: LockStateChangeFailed: findAndModify query predicate didn't match any lock document
2018-04-30T18:35:58.158+0000 I COMMAND  [conn3] Assigning UUID a53c9ec4-2df9-45d6-b581-6641d800df07 to collection local.system.rollback.id
2018-04-30T18:35:58.158+0000 I COMMAND  [conn3] Assigning UUID 9e969eb8-00be-45fd-a66f-263db66f166c to collection local.system.replset
2018-04-30T18:35:58.159+0000 I COMMAND  [conn3] Assigning UUID 88f29aa7-a88a-4fd0-b2a2-09f9123fdcb7 to collection local.me
2018-04-30T18:35:58.159+0000 I COMMAND  [conn3] Assigning UUID 4cc54d04-9a1a-4d3a-b121-a4d15235a0c1 to collection local.startup_log
2018-04-30T18:35:58.159+0000 I COMMAND  [conn3] Assigning UUID ecefce92-6f0d-4595-85a9-250b4e1cc5df to collection local.replset.minvalid
2018-04-30T18:35:58.159+0000 I COMMAND  [conn3] Assigning UUID c66413a4-596b-44a4-92bd-60310b9e89c5 to collection local.oplog.rs
2018-04-30T18:35:58.159+0000 I COMMAND  [conn3] Assigning UUID 7630000b-3d21-4b57-b28e-7a01c2d15208 to collection local.replset.election
2018-04-30T18:35:58.160+0000 I COMMAND  [conn3] Assigning UUID a755b352-5cc1-4fd2-9f5c-ab3bf64e183d to collection admin.system.version
2018-04-30T18:35:58.160+0000 I COMMAND  [conn3] Assigning UUID e0dcfbc6-8555-4400-8ba1-a8b64b6f17c1 to collection config.transactions
2018-04-30T18:35:58.160+0000 I COMMAND  [conn3] Finished updating UUID schema version for upgrade, waiting for all UUIDs to be committed.
2018-04-30T18:35:58.158+0000 I NETWORK  [shard registry reload] Starting new replica set monitor for s0/localhost:37017
2018-04-30T18:35:58.158+0000 I ASIO     [NetworkInterfaceASIO-ShardRegistry-0] Successfully connected to localhost:57050, took 3ms (3 connections now open to localhost:57050)
2018-04-30T18:35:58.161+0000 I ASIO     [NetworkInterfaceASIO-ShardRegistry-0] Successfully connected to localhost:57050, took 4ms (3 connections now open to localhost:57050)
2018-04-30T18:35:58.161+0000 I COMMAND  [conn3] setting featureCompatibilityVersion to 3.6
2018-04-30T18:35:58.162+0000 I NETWORK  [conn3] Skip closing connection for connection # 3
2018-04-30T18:35:58.162+0000 I NETWORK  [conn3] Skip closing connection for connection # 2
2018-04-30T18:35:58.162+0000 I NETWORK  [ReplicaSetMonitor-TaskExecutor-0] Successfully connected to localhost:37017 (1 connections now open to localhost:37017 with a 5 second timeout)
2018-04-30T18:35:58.165+0000 I NETWORK  [listener] connection accepted from 127.0.0.1:55096 #4 (3 connections now open)
2018-04-30T18:35:58.166+0000 I NETWORK  [conn4] received client metadata from 127.0.0.1:55096 conn4: { driver: { name: "MongoDB Internal Client", version: "3.6.4" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2018-04-30T18:35:58.181+0000 I NETWORK  [listener] connection accepted from 127.0.0.1:55120 #5 (4 connections now open)
2018-04-30T18:35:58.182+0000 I NETWORK  [conn5] received client metadata from 127.0.0.1:55120 conn5: { driver: { name: "MongoDB Internal Client", version: "3.6.4" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2018-04-30T18:35:58.205+0000 I NETWORK  [listener] connection accepted from 127.0.0.1:55130 #6 (5 connections now open)
2018-04-30T18:35:58.205+0000 I NETWORK  [conn6] received client metadata from 127.0.0.1:55130 conn6: { driver: { name: "NetworkInterfaceASIO-ShardRegistry", version: "3.6.4" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2018-04-30T18:35:58.357+0000 I NETWORK  [listener] connection accepted from 127.0.0.1:55140 #7 (6 connections now open)
2018-04-30T18:35:58.358+0000 I NETWORK  [conn7] received client metadata from 127.0.0.1:55140 conn7: { driver: { name: "MongoDB Internal Client", version: "3.6.4" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2018-04-30T18:36:28.163+0000 I NETWORK  [shard registry reload] Starting new replica set monitor for s1/localhost:47017
2018-04-30T18:36:28.164+0000 I NETWORK  [shard registry reload] Starting new replica set monitor for s2/localhost:57017
2018-04-30T18:36:28.164+0000 I NETWORK  [listener] connection accepted from 127.0.0.1:55148 #8 (7 connections now open)
2018-04-30T18:36:28.167+0000 I NETWORK  [conn8] received client metadata from 127.0.0.1:55148 conn8: { driver: { name: "MongoDB Internal Client", version: "3.6.4" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2018-04-30T18:36:28.168+0000 I NETWORK  [ReplicaSetMonitor-TaskExecutor-0] Successfully connected to localhost:47017 (1 connections now open to localhost:47017 with a 5 second timeout)
2018-04-30T18:36:28.177+0000 I NETWORK  [ReplicaSetMonitor-TaskExecutor-0] Successfully connected to localhost:57017 (1 connections now open to localhost:57017 with a 5 second timeout)
2018-04-30T18:36:48.185+0000 I NETWORK  [listener] connection accepted from 127.0.0.1:55248 #9 (8 connections now open)
2018-04-30T18:36:48.187+0000 I NETWORK  [conn9] received client metadata from 127.0.0.1:55248 conn9: { driver: { name: "NetworkInterfaceASIO-TaskExecutorPool-3", version: "3.6.4" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2018-04-30T18:36:51.039+0000 I NETWORK  [listener] connection accepted from 127.0.0.1:55254 #10 (9 connections now open)
2018-04-30T18:36:51.049+0000 I NETWORK  [conn10] received client metadata from 127.0.0.1:55254 conn10: { driver: { name: "NetworkInterfaceASIO-ShardRegistry", version: "3.6.4" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2018-04-30T18:36:51.060+0000 I SHARDING [conn10] Refreshing chunks for collection accidents.accidents based on version 0|0||000000000000000000000000
2018-04-30T18:36:51.186+0000 I SHARDING [ConfigServerCatalogCacheLoader-0] Cache loader remotely refreshed for collection accidents.accidents from collection version 0|0||000000000000000000000000 and found collection version 2|4||5ae7620e1b1b0bfabb4ae6f5
2018-04-30T18:36:51.186+0000 I STORAGE  [ShardServerCatalogCacheLoader-0] createCollection: config.cache.collections with generated UUID: a8c41649-2558-4719-b586-ac8e727358ed
2018-04-30T18:36:51.208+0000 I SHARDING [ConfigServerCatalogCacheLoader-0] Cache loader found enqueued metadata from 1|3||5ae7620e1b1b0bfabb4ae6f5 to 2|4||5ae7620e1b1b0bfabb4ae6f5 and no persisted metadata, GTE cache version 0|0||000000000000000000000000
2018-04-30T18:36:51.209+0000 I SHARDING [ConfigServerCatalogCacheLoader-0] Refresh for collection accidents.accidents took 148 ms and found version 2|4||5ae7620e1b1b0bfabb4ae6f5
2018-04-30T18:36:51.209+0000 I SHARDING [conn10] Marking collection accidents.accidents as sharded with collection version: 2|4||5ae7620e1b1b0bfabb4ae6f5, shard version: 0|0||5ae7620e1b1b0bfabb4ae6f5
2018-04-30T18:36:51.210+0000 I COMMAND  [conn10] command admin.$cmd command: _recvChunkStart { _recvChunkStart: "accidents.accidents", sessionId: "s0_s1_5ae76242fbc4b16e77d6366f", from: "s0/localhost:37017", fromShardName: "s0", toShardName: "s1", min: { Accident_Index: "200901BS70002" }, max: { Accident_Index: "200901RY10442" }, shardKeyPattern: { Accident_Index: 1.0 }, $clusterTime: { clusterTime: Timestamp(1525113411, 104), signature: { hash: BinData(0, 882DBC3429313963B2239FA3971DBB74C5F597FE), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113410, 17025), t: 1 } }, $db: "admin" } numYields:0 reslen:298 locks:{ Global: { acquireCount: { r: 3, w: 1 } }, Database: { acquireCount: { r: 1, w: 1 } }, Collection: { acquireCount: { r: 1, W: 1 } } } protocol:op_msg 150ms
2018-04-30T18:36:51.210+0000 I STORAGE  [ShardServerCatalogCacheLoader-0] createCollection: config.cache.chunks.accidents.accidents with generated UUID: d4f828ef-ea5f-4076-81b7-07af0fc4dc0d
2018-04-30T18:36:51.221+0000 I SHARDING [migrateThread] Starting receiving end of migration of chunk { Accident_Index: "200901BS70002" } -> { Accident_Index: "200901RY10442" } for collection accidents.accidents from s0/localhost:37017 at epoch 5ae7620e1b1b0bfabb4ae6f5 with session id s0_s1_5ae76242fbc4b16e77d6366f
2018-04-30T18:36:51.223+0000 I NETWORK  [migrateThread] Successfully connected to s0/localhost:37017 (1 connections now open to s0/localhost:37017 with a 0 second timeout)
2018-04-30T18:36:51.239+0000 I INDEX    [ShardServerCatalogCacheLoader-0] build index on: config.cache.chunks.accidents.accidents properties: { v: 2, key: { lastmod: 1 }, name: "lastmod_1", ns: "config.cache.chunks.accidents.accidents" }
2018-04-30T18:36:51.251+0000 I INDEX    [ShardServerCatalogCacheLoader-0] 	 building index using bulk method; build may temporarily use up to 500 megabytes of RAM
2018-04-30T18:36:51.257+0000 I INDEX    [ShardServerCatalogCacheLoader-0] build index done.  scanned 0 total records. 0 secs
2018-04-30T18:36:51.266+0000 I STORAGE  [migrateThread] createCollection: accidents.accidents with provided UUID: 152b57c2-bad9-46dd-aa0a-3a8e8cf740aa
2018-04-30T18:36:51.284+0000 I INDEX    [migrateThread] build index on: accidents.accidents properties: { v: 2, key: { Accident_Index: 1.0 }, name: "Accident_Index_1", ns: "accidents.accidents" }
2018-04-30T18:36:51.284+0000 I INDEX    [migrateThread] 	 building index using bulk method; build may temporarily use up to 500 megabytes of RAM
2018-04-30T18:36:51.285+0000 I SHARDING [migrateThread] Scheduling deletion of any documents in accidents.accidents range [{ Accident_Index: "200901BS70002" }, { Accident_Index: "200901RY10442" }) before migrating in a chunk covering the range
2018-04-30T18:36:51.285+0000 I SHARDING [Collection Range Deleter] No documents remain to delete in accidents.accidents range [{ Accident_Index: "200901BS70002" }, { Accident_Index: "200901RY10442" })
2018-04-30T18:36:51.286+0000 I SHARDING [Collection Range Deleter] Waiting for majority replication of local deletions in accidents.accidents range [{ Accident_Index: "200901BS70002" }, { Accident_Index: "200901RY10442" })
2018-04-30T18:36:51.286+0000 I SHARDING [Collection Range Deleter] Finished deleting documents in accidents.accidents range [{ Accident_Index: "200901BS70002" }, { Accident_Index: "200901RY10442" })
2018-04-30T18:36:51.286+0000 I SHARDING [migrateThread] Finished deleting accidents.accidents range [{ Accident_Index: "200901BS70002" }, { Accident_Index: "200901RY10442" })
2018-04-30T18:36:51.300+0000 I ASIO     [NetworkInterfaceASIO-ShardRegistry-0] Connecting to localhost:37017
2018-04-30T18:36:51.315+0000 I ASIO     [NetworkInterfaceASIO-ShardRegistry-0] Successfully connected to localhost:37017, took 15ms (1 connections now open to localhost:37017)
2018-04-30T18:36:52.212+0000 I COMMAND  [conn10] command admin.$cmd command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s0_s1_5ae76242fbc4b16e77d6366f", $clusterTime: { clusterTime: Timestamp(1525113411, 2000), signature: { hash: BinData(0, 882DBC3429313963B2239FA3971DBB74C5F597FE), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113410, 17025), t: 1 } }, $db: "admin" } numYields:0 reslen:643 locks:{} protocol:op_msg 1001ms
2018-04-30T18:36:53.217+0000 I COMMAND  [conn10] command admin.$cmd command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s0_s1_5ae76242fbc4b16e77d6366f", $clusterTime: { clusterTime: Timestamp(1525113412, 2000), signature: { hash: BinData(0, E60D95ACF47703A529456B43F05B9A02EA8D17AE), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113410, 17025), t: 1 } }, $db: "admin" } numYields:0 reslen:643 locks:{} protocol:op_msg 1003ms
2018-04-30T18:36:54.220+0000 I COMMAND  [conn10] command admin.$cmd command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s0_s1_5ae76242fbc4b16e77d6366f", $clusterTime: { clusterTime: Timestamp(1525113413, 2576), signature: { hash: BinData(0, 640A4843C1BF091175AB87D077D8CED03E89B1CE), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113410, 17025), t: 1 } }, $db: "admin" } numYields:0 reslen:643 locks:{} protocol:op_msg 1001ms
2018-04-30T18:36:55.221+0000 I COMMAND  [conn10] command admin.$cmd command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s0_s1_5ae76242fbc4b16e77d6366f", $clusterTime: { clusterTime: Timestamp(1525113414, 1448), signature: { hash: BinData(0, 8B14F0D31A7FCB1955C34832C8FBBA709C1B9582), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113413, 7001), t: 1 } }, $db: "admin" } numYields:0 reslen:643 locks:{} protocol:op_msg 1000ms
2018-04-30T18:36:56.222+0000 I COMMAND  [conn10] command admin.$cmd command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s0_s1_5ae76242fbc4b16e77d6366f", $clusterTime: { clusterTime: Timestamp(1525113415, 2320), signature: { hash: BinData(0, AFD220F3EBE0A54F440CFC41190A97E9874CA4F8), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113413, 7001), t: 1 } }, $db: "admin" } numYields:0 reslen:643 locks:{} protocol:op_msg 999ms
2018-04-30T18:36:57.223+0000 I COMMAND  [conn10] command admin.$cmd command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s0_s1_5ae76242fbc4b16e77d6366f", $clusterTime: { clusterTime: Timestamp(1525113416, 1912), signature: { hash: BinData(0, 2795B8675065D1EAD0ED80EFED5F87D6153CE1ED), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113415, 7553), t: 1 } }, $db: "admin" } numYields:0 reslen:643 locks:{} protocol:op_msg 999ms
2018-04-30T18:36:58.231+0000 I COMMAND  [conn10] command admin.$cmd command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s0_s1_5ae76242fbc4b16e77d6366f", $clusterTime: { clusterTime: Timestamp(1525113417, 1118), signature: { hash: BinData(0, 102144BF71EE249560EB3C82F08C756416E6D19B), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113415, 7553), t: 1 } }, $db: "admin" } numYields:0 reslen:643 locks:{} protocol:op_msg 999ms
2018-04-30T18:36:59.233+0000 I COMMAND  [conn10] command admin.$cmd command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s0_s1_5ae76242fbc4b16e77d6366f", $clusterTime: { clusterTime: Timestamp(1525113418, 896), signature: { hash: BinData(0, C9CA578409B11FC35859C739F17230FA87968A06), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113418, 526), t: 1 } }, $db: "admin" } numYields:0 reslen:643 locks:{} protocol:op_msg 1000ms
2018-04-30T18:37:00.236+0000 I COMMAND  [conn10] command admin.$cmd command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s0_s1_5ae76242fbc4b16e77d6366f", $clusterTime: { clusterTime: Timestamp(1525113419, 2260), signature: { hash: BinData(0, 5ECA54043D2C1A034B9E29F628EF14D6243A0D08), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113418, 526), t: 1 } }, $db: "admin" } numYields:0 reslen:643 locks:{} protocol:op_msg 1000ms
2018-04-30T18:37:01.238+0000 I COMMAND  [conn10] command admin.$cmd command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s0_s1_5ae76242fbc4b16e77d6366f", $clusterTime: { clusterTime: Timestamp(1525113420, 410), signature: { hash: BinData(0, BF6FC7C2D69330877C3E7DD1EFFA60BACCE33CEF), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113418, 526), t: 1 } }, $db: "admin" } numYields:0 reslen:643 locks:{} protocol:op_msg 1000ms
2018-04-30T18:37:02.241+0000 I COMMAND  [conn10] command admin.$cmd command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s0_s1_5ae76242fbc4b16e77d6366f", $clusterTime: { clusterTime: Timestamp(1525113421, 1224), signature: { hash: BinData(0, C3E6BB41174625CEE7D534A268C884F8D03F0EC0), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113418, 526), t: 1 } }, $db: "admin" } numYields:0 reslen:643 locks:{} protocol:op_msg 1001ms
2018-04-30T18:37:03.244+0000 I COMMAND  [conn10] command admin.$cmd command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s0_s1_5ae76242fbc4b16e77d6366f", $clusterTime: { clusterTime: Timestamp(1525113422, 1234), signature: { hash: BinData(0, D399165F8BEC99DCC86E1E59D96F5CFFC61AE817), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113418, 526), t: 1 } }, $db: "admin" } numYields:0 reslen:643 locks:{} protocol:op_msg 999ms
2018-04-30T18:37:03.812+0000 I SHARDING [migrateThread] Waiting for replication to catch up before entering critical section
2018-04-30T18:37:03.812+0000 I SHARDING [migrateThread] migrate commit succeeded flushing to secondaries for 'accidents.accidents' { Accident_Index: "200901BS70002" } -> { Accident_Index: "200901RY10442" }
2018-04-30T18:37:03.813+0000 I COMMAND  [conn10] command admin.$cmd command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s0_s1_5ae76242fbc4b16e77d6366f", $clusterTime: { clusterTime: Timestamp(1525113423, 1981), signature: { hash: BinData(0, 2A707CB6D894D5704CBCB0C92A9C1B2F06114C8A), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113418, 526), t: 1 } }, $db: "admin" } numYields:0 reslen:644 locks:{} protocol:op_msg 564ms
2018-04-30T18:37:03.878+0000 I SHARDING [migrateThread] migrate commit succeeded flushing to secondaries for 'accidents.accidents' { Accident_Index: "200901BS70002" } -> { Accident_Index: "200901RY10442" }
2018-04-30T18:37:04.099+0000 I SHARDING [migrateThread] about to log metadata event into changelog: { _id: "tm351-18J-test-student-2018-04-30T18:37:04.096+0000-5ae76250b3f9f8ea6914d69c", server: "tm351-18J-test-student", clientAddr: "", time: new Date(1525113424096), what: "moveChunk.to", ns: "accidents.accidents", details: { min: { Accident_Index: "200901BS70002" }, max: { Accident_Index: "200901RY10442" }, step 1 of 6: 62, step 2 of 6: 1, step 3 of 6: 12518, step 4 of 6: 7, step 5 of 6: 66, step 6 of 6: 213, note: "success" } }
2018-04-30T18:37:04.109+0000 I COMMAND  [conn10] command admin.$cmd command: _recvChunkCommit { _recvChunkCommit: "accidents.accidents", waitForSteadyOrDone: false, sessionId: "s0_s1_5ae76242fbc4b16e77d6366f", $clusterTime: { clusterTime: Timestamp(1525113423, 6104), signature: { hash: BinData(0, 2A707CB6D894D5704CBCB0C92A9C1B2F06114C8A), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113418, 526), t: 1 } }, $db: "admin" } numYields:0 reslen:587 locks:{} protocol:op_msg 241ms
2018-04-30T18:37:05.318+0000 I SHARDING [conn10] Refreshing chunks for collection accidents.accidents based on version 2|4||5ae7620e1b1b0bfabb4ae6f5
2018-04-30T18:37:05.331+0000 I SHARDING [ConfigServerCatalogCacheLoader-0] Cache loader remotely refreshed for collection accidents.accidents from collection version 2|4||5ae7620e1b1b0bfabb4ae6f5 and found collection version 4|1||5ae7620e1b1b0bfabb4ae6f5
2018-04-30T18:37:05.339+0000 I SHARDING [ConfigServerCatalogCacheLoader-0] Cache loader found enqueued metadata from 2|4||5ae7620e1b1b0bfabb4ae6f5 to 4|1||5ae7620e1b1b0bfabb4ae6f5 and persisted metadata from 2|4||5ae7620e1b1b0bfabb4ae6f5 to 4|1||5ae7620e1b1b0bfabb4ae6f5, GTE cache version 2|4||5ae7620e1b1b0bfabb4ae6f5
2018-04-30T18:37:05.339+0000 I SHARDING [ConfigServerCatalogCacheLoader-0] Refresh for collection accidents.accidents took 20 ms and found version 4|1||5ae7620e1b1b0bfabb4ae6f5
2018-04-30T18:37:05.339+0000 I SHARDING [conn10] Updating collection metadata for accidents.accidents from collection version: 2|4||5ae7620e1b1b0bfabb4ae6f5, shard version: 0|0||5ae7620e1b1b0bfabb4ae6f5 to collection version: 4|1||5ae7620e1b1b0bfabb4ae6f5, shard version: 3|0||5ae7620e1b1b0bfabb4ae6f5
2018-04-30T18:37:05.353+0000 I SHARDING [migrateThread] Starting receiving end of migration of chunk { Accident_Index: "200901RY10442" } -> { Accident_Index: "200905AA31857" } for collection accidents.accidents from s0/localhost:37017 at epoch 5ae7620e1b1b0bfabb4ae6f5 with session id s0_s1_5ae76251fbc4b16e77d63815
2018-04-30T18:37:05.359+0000 I SHARDING [migrateThread] Scheduling deletion of any documents in accidents.accidents range [{ Accident_Index: "200901RY10442" }, { Accident_Index: "200905AA31857" }) before migrating in a chunk covering the range
2018-04-30T18:37:05.361+0000 I SHARDING [Collection Range Deleter] No documents remain to delete in accidents.accidents range [{ Accident_Index: "200901RY10442" }, { Accident_Index: "200905AA31857" })
2018-04-30T18:37:05.362+0000 I SHARDING [Collection Range Deleter] Waiting for majority replication of local deletions in accidents.accidents range [{ Accident_Index: "200901RY10442" }, { Accident_Index: "200905AA31857" })
2018-04-30T18:37:05.362+0000 I SHARDING [Collection Range Deleter] Finished deleting documents in accidents.accidents range [{ Accident_Index: "200901RY10442" }, { Accident_Index: "200905AA31857" })
2018-04-30T18:37:05.362+0000 I SHARDING [migrateThread] Finished deleting accidents.accidents range [{ Accident_Index: "200901RY10442" }, { Accident_Index: "200905AA31857" })
2018-04-30T18:37:06.389+0000 I COMMAND  [conn10] command admin.$cmd appName: "MongoDB Shell" command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s0_s1_5ae76251fbc4b16e77d63815", $clusterTime: { clusterTime: Timestamp(1525113425, 2707), signature: { hash: BinData(0, DB2259CAB560C45AB91C7EE945C414B1250A07E3), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113425, 2688), t: 1 } }, $db: "admin" } numYields:0 reslen:643 locks:{} protocol:op_msg 1020ms
2018-04-30T18:37:07.429+0000 I COMMAND  [conn10] command admin.$cmd appName: "MongoDB Shell" command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s0_s1_5ae76251fbc4b16e77d63815", $clusterTime: { clusterTime: Timestamp(1525113426, 1058), signature: { hash: BinData(0, FB37A505EE47265E6C8B2F71724C6153D784D6CC), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113426, 1), t: 1 } }, $db: "admin" } numYields:0 reslen:643 locks:{} protocol:op_msg 1005ms
2018-04-30T18:37:08.654+0000 I COMMAND  [conn10] command admin.$cmd appName: "MongoDB Shell" command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s0_s1_5ae76251fbc4b16e77d63815", $clusterTime: { clusterTime: Timestamp(1525113427, 2669), signature: { hash: BinData(0, 7D7181F08D341A2B8FFF3A7088D3F417D4414F47), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113426, 1), t: 1 } }, $db: "admin" } numYields:0 reslen:643 locks:{} protocol:op_msg 1010ms
2018-04-30T18:37:09.716+0000 I COMMAND  [conn10] command admin.$cmd appName: "MongoDB Shell" command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s0_s1_5ae76251fbc4b16e77d63815", $clusterTime: { clusterTime: Timestamp(1525113428, 3575), signature: { hash: BinData(0, FEED809426E167BC3192C75802D934100EED832A), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113426, 1), t: 1 } }, $db: "admin" } numYields:0 reslen:643 locks:{} protocol:op_msg 1001ms
2018-04-30T18:37:10.739+0000 I COMMAND  [conn10] command admin.$cmd appName: "MongoDB Shell" command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s0_s1_5ae76251fbc4b16e77d63815", $clusterTime: { clusterTime: Timestamp(1525113429, 728), signature: { hash: BinData(0, 12EDAEB3939CB7BB0A16475D79EA2706EEA933C3), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113426, 1), t: 1 } }, $db: "admin" } numYields:0 reslen:643 locks:{} protocol:op_msg 1015ms
2018-04-30T18:37:11.751+0000 I COMMAND  [conn10] command admin.$cmd appName: "MongoDB Shell" command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s0_s1_5ae76251fbc4b16e77d63815", $clusterTime: { clusterTime: Timestamp(1525113430, 3364), signature: { hash: BinData(0, 1CF44D0F28D6A4968830445B6CBB7AFA25034E46), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113426, 1), t: 1 } }, $db: "admin" } numYields:0 reslen:643 locks:{} protocol:op_msg 1001ms
2018-04-30T18:37:12.790+0000 I COMMAND  [conn10] command admin.$cmd appName: "MongoDB Shell" command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s0_s1_5ae76251fbc4b16e77d63815", $clusterTime: { clusterTime: Timestamp(1525113431, 940), signature: { hash: BinData(0, 3D173E6830169FD590E4A11F8B9764A766BF63B6), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113426, 1), t: 1 } }, $db: "admin" } numYields:0 reslen:643 locks:{} protocol:op_msg 1017ms
2018-04-30T18:37:14.417+0000 I COMMAND  [conn10] command admin.$cmd appName: "MongoDB Shell" command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s0_s1_5ae76251fbc4b16e77d63815", $clusterTime: { clusterTime: Timestamp(1525113432, 3114), signature: { hash: BinData(0, 85A9B425CA9CDF631F3F522E03E31F709BB7B4D5), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113426, 1), t: 1 } }, $db: "admin" } numYields:0 reslen:643 locks:{} protocol:op_msg 1041ms
2018-04-30T18:37:15.465+0000 I COMMAND  [conn10] command admin.$cmd appName: "MongoDB Shell" command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s0_s1_5ae76251fbc4b16e77d63815", $clusterTime: { clusterTime: Timestamp(1525113434, 1), signature: { hash: BinData(0, 8B864C41290A727CA1D669E2B1EECAC9BE1ADFB0), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113426, 1), t: 1 } }, $db: "admin" } numYields:0 reslen:643 locks:{} protocol:op_msg 1010ms
2018-04-30T18:37:16.739+0000 I COMMAND  [conn10] command admin.$cmd appName: "MongoDB Shell" command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s0_s1_5ae76251fbc4b16e77d63815", $clusterTime: { clusterTime: Timestamp(1525113435, 129), signature: { hash: BinData(0, 9A3E6C4EAE9475D9645B70B41B71E6E37AE86C52), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113426, 1), t: 1 } }, $db: "admin" } numYields:0 reslen:643 locks:{} protocol:op_msg 1094ms
2018-04-30T18:37:18.274+0000 I COMMAND  [conn10] command admin.$cmd appName: "MongoDB Shell" command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s0_s1_5ae76251fbc4b16e77d63815", $clusterTime: { clusterTime: Timestamp(1525113436, 67), signature: { hash: BinData(0, 0180D7B20C5AABE7DEBE4D3B67A39D0E27F51613), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113426, 1), t: 1 } }, $db: "admin" } numYields:0 reslen:643 locks:{} protocol:op_msg 1083ms
2018-04-30T18:37:20.331+0000 I COMMAND  [conn10] command admin.$cmd appName: "MongoDB Shell" command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s0_s1_5ae76251fbc4b16e77d63815", $clusterTime: { clusterTime: Timestamp(1525113438, 64), signature: { hash: BinData(0, C77B07CE232216763CDD4ACD7CA1DC21707B059D), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113436, 1), t: 1 } }, $db: "admin" } numYields:0 reslen:643 locks:{} protocol:op_msg 1057ms
2018-04-30T18:37:21.987+0000 I COMMAND  [conn10] command admin.$cmd appName: "MongoDB Shell" command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s0_s1_5ae76251fbc4b16e77d63815", $clusterTime: { clusterTime: Timestamp(1525113440, 1), signature: { hash: BinData(0, AC17699881F052437909D0143DC7D29A8E92B32D), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113436, 1), t: 1 } }, $db: "admin" } numYields:0 reslen:643 locks:{} protocol:op_msg 1074ms
2018-04-30T18:37:23.532+0000 I COMMAND  [conn10] command admin.$cmd appName: "MongoDB Shell" command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s0_s1_5ae76251fbc4b16e77d63815", $clusterTime: { clusterTime: Timestamp(1525113441, 30), signature: { hash: BinData(0, 9D8BE76607F044FCCC27BA522A3A56736F11881B), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113436, 1), t: 1 } }, $db: "admin" } numYields:0 reslen:643 locks:{} protocol:op_msg 1055ms
2018-04-30T18:37:24.958+0000 I COMMAND  [conn10] command admin.$cmd appName: "MongoDB Shell" command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s0_s1_5ae76251fbc4b16e77d63815", $clusterTime: { clusterTime: Timestamp(1525113443, 74), signature: { hash: BinData(0, 39798F5C155F25F8C98224079D2DD497505DEE0C), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113436, 1), t: 1 } }, $db: "admin" } numYields:0 reslen:643 locks:{} protocol:op_msg 1083ms
2018-04-30T18:37:26.173+0000 I COMMAND  [conn10] command admin.$cmd appName: "MongoDB Shell" command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s0_s1_5ae76251fbc4b16e77d63815", $clusterTime: { clusterTime: Timestamp(1525113444, 1), signature: { hash: BinData(0, 0AC1AAA1AFD78A53F110B387D6F9E5F8CFA1E48A), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113436, 1), t: 1 } }, $db: "admin" } numYields:0 reslen:643 locks:{} protocol:op_msg 1099ms
2018-04-30T18:37:27.892+0000 I COMMAND  [conn10] command admin.$cmd appName: "MongoDB Shell" command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s0_s1_5ae76251fbc4b16e77d63815", $clusterTime: { clusterTime: Timestamp(1525113445, 30), signature: { hash: BinData(0, E8EC0A3DBD22B62FCC39A6F4F5A26327EE6E3326), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113436, 1), t: 1 } }, $db: "admin" } numYields:0 reslen:643 locks:{} protocol:op_msg 1059ms
2018-04-30T18:37:28.213+0000 I ASIO     [NetworkInterfaceASIO-ShardRegistry-0] Ending idle connection to host localhost:57050 because the pool meets constraints; 2 connections to that host remain open
2018-04-30T18:37:29.466+0000 I COMMAND  [conn10] command admin.$cmd appName: "MongoDB Shell" command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s0_s1_5ae76251fbc4b16e77d63815", $clusterTime: { clusterTime: Timestamp(1525113447, 65), signature: { hash: BinData(0, BD408DCD473FDA54E8481C0811A7294C0E2646E4), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113436, 1), t: 1 } }, $db: "admin" } numYields:0 reslen:643 locks:{} protocol:op_msg 1325ms
2018-04-30T18:37:31.456+0000 I NETWORK  [conn10] end connection 127.0.0.1:55254 (8 connections now open)
2018-04-30T18:37:31.460+0000 I NETWORK  [NetworkInterfaceASIO-ShardRegistry-0] Marking host localhost:37017 as failed :: caused by :: HostUnreachable: End of file
2018-04-30T18:37:31.462+0000 I ASIO     [NetworkInterfaceASIO-ShardRegistry-0] Ending connection to host localhost:37017 due to bad connection status; 0 connections to that host remain open
2018-04-30T18:37:31.470+0000 I NETWORK  [conn7] end connection 127.0.0.1:55140 (7 connections now open)
2018-04-30T18:37:31.474+0000 I NETWORK  [ReplicaSetMonitor-TaskExecutor-0] Socket closed remotely, no longer connected (idle 33 secs, remote host 127.0.0.1:37017)
2018-04-30T18:37:31.493+0000 I NETWORK  [ReplicaSetMonitor-TaskExecutor-0] Socket say send() Connection reset by peer 127.0.0.1:37017
2018-04-30T18:37:31.542+0000 W NETWORK  [ReplicaSetMonitor-TaskExecutor-0] Unable to reach primary for set s0
2018-04-30T18:37:31.543+0000 I NETWORK  [ReplicaSetMonitor-TaskExecutor-0] Cannot reach any nodes for set s0. Please check network connectivity and the status of the set. This has happened for 1 checks in a row.
2018-04-30T18:37:35.124+0000 W NETWORK  [migrateThread] Failed to connect to 127.0.0.1:37017, in(checking socket for error after poll), reason: Connection refused
2018-04-30T18:37:35.124+0000 W NETWORK  [migrateThread] Unable to reach primary for set s0
2018-04-30T18:37:35.125+0000 I NETWORK  [migrateThread] Cannot reach any nodes for set s0. Please check network connectivity and the status of the set. This has happened for 2 checks in a row.
2018-04-30T18:37:35.625+0000 W NETWORK  [migrateThread] Failed to connect to 127.0.0.1:37017, in(checking socket for error after poll), reason: Connection refused
2018-04-30T18:37:35.626+0000 W NETWORK  [migrateThread] Unable to reach primary for set s0
2018-04-30T18:37:35.626+0000 I NETWORK  [migrateThread] Cannot reach any nodes for set s0. Please check network connectivity and the status of the set. This has happened for 3 checks in a row.
2018-04-30T18:37:36.128+0000 W NETWORK  [migrateThread] Failed to connect to 127.0.0.1:37017, in(checking socket for error after poll), reason: Connection refused
2018-04-30T18:37:36.129+0000 W NETWORK  [migrateThread] Unable to reach primary for set s0
2018-04-30T18:37:36.129+0000 I NETWORK  [migrateThread] Cannot reach any nodes for set s0. Please check network connectivity and the status of the set. This has happened for 4 checks in a row.
2018-04-30T18:37:36.634+0000 W NETWORK  [migrateThread] Failed to connect to 127.0.0.1:37017, in(checking socket for error after poll), reason: Connection refused
2018-04-30T18:37:36.635+0000 W NETWORK  [migrateThread] Unable to reach primary for set s0
2018-04-30T18:37:36.636+0000 I NETWORK  [migrateThread] Cannot reach any nodes for set s0. Please check network connectivity and the status of the set. This has happened for 5 checks in a row.
2018-04-30T18:37:37.136+0000 W NETWORK  [migrateThread] Failed to connect to 127.0.0.1:37017, in(checking socket for error after poll), reason: Connection refused
2018-04-30T18:37:37.137+0000 W NETWORK  [migrateThread] Unable to reach primary for set s0
2018-04-30T18:37:37.137+0000 I NETWORK  [migrateThread] Cannot reach any nodes for set s0. Please check network connectivity and the status of the set. This has happened for 6 checks in a row.
2018-04-30T18:37:37.637+0000 W NETWORK  [migrateThread] Failed to connect to 127.0.0.1:37017, in(checking socket for error after poll), reason: Connection refused
2018-04-30T18:37:37.638+0000 W NETWORK  [migrateThread] Unable to reach primary for set s0
2018-04-30T18:37:37.638+0000 I NETWORK  [migrateThread] Cannot reach any nodes for set s0. Please check network connectivity and the status of the set. This has happened for 7 checks in a row.
2018-04-30T18:37:38.139+0000 W NETWORK  [migrateThread] Failed to connect to 127.0.0.1:37017, in(checking socket for error after poll), reason: Connection refused
2018-04-30T18:37:38.140+0000 W NETWORK  [migrateThread] Unable to reach primary for set s0
2018-04-30T18:37:38.140+0000 I NETWORK  [migrateThread] Cannot reach any nodes for set s0. Please check network connectivity and the status of the set. This has happened for 8 checks in a row.
2018-04-30T18:37:38.641+0000 W NETWORK  [migrateThread] Failed to connect to 127.0.0.1:37017, in(checking socket for error after poll), reason: Connection refused
2018-04-30T18:37:38.641+0000 W NETWORK  [migrateThread] Unable to reach primary for set s0
2018-04-30T18:37:38.641+0000 I NETWORK  [migrateThread] Cannot reach any nodes for set s0. Please check network connectivity and the status of the set. This has happened for 9 checks in a row.
2018-04-30T18:37:39.149+0000 W NETWORK  [migrateThread] Failed to connect to 127.0.0.1:37017, in(checking socket for error after poll), reason: Connection refused
2018-04-30T18:37:39.151+0000 W NETWORK  [migrateThread] Unable to reach primary for set s0
2018-04-30T18:37:39.151+0000 I NETWORK  [migrateThread] Cannot reach any nodes for set s0. Please check network connectivity and the status of the set. This has happened for 10 checks in a row.
2018-04-30T18:37:39.652+0000 W NETWORK  [migrateThread] Failed to connect to 127.0.0.1:37017, in(checking socket for error after poll), reason: Connection refused
2018-04-30T18:37:39.652+0000 W NETWORK  [migrateThread] Unable to reach primary for set s0
2018-04-30T18:37:39.653+0000 I NETWORK  [migrateThread] Cannot reach any nodes for set s0. Please check network connectivity and the status of the set. This has happened for 11 checks in a row.
2018-04-30T18:37:40.156+0000 W NETWORK  [migrateThread] Failed to connect to 127.0.0.1:37017, in(checking socket for error after poll), reason: Connection refused
2018-04-30T18:37:40.156+0000 W NETWORK  [migrateThread] Unable to reach primary for set s0
2018-04-30T18:37:40.657+0000 W NETWORK  [migrateThread] Failed to connect to 127.0.0.1:37017, in(checking socket for error after poll), reason: Connection refused
2018-04-30T18:37:40.658+0000 W NETWORK  [migrateThread] Unable to reach primary for set s0
2018-04-30T18:37:41.158+0000 W NETWORK  [migrateThread] Failed to connect to 127.0.0.1:37017, in(checking socket for error after poll), reason: Connection refused
2018-04-30T18:37:41.162+0000 W NETWORK  [migrateThread] Unable to reach primary for set s0
2018-04-30T18:37:41.663+0000 W NETWORK  [migrateThread] Failed to connect to 127.0.0.1:37017, in(checking socket for error after poll), reason: Connection refused
2018-04-30T18:37:41.664+0000 W NETWORK  [migrateThread] Unable to reach primary for set s0
2018-04-30T18:37:42.165+0000 W NETWORK  [migrateThread] Failed to connect to 127.0.0.1:37017, in(checking socket for error after poll), reason: Connection refused
2018-04-30T18:37:42.166+0000 W NETWORK  [migrateThread] Unable to reach primary for set s0
2018-04-30T18:37:42.667+0000 W NETWORK  [migrateThread] Failed to connect to 127.0.0.1:37017, in(checking socket for error after poll), reason: Connection refused
2018-04-30T18:37:42.667+0000 W NETWORK  [migrateThread] Unable to reach primary for set s0
2018-04-30T18:37:43.174+0000 W NETWORK  [migrateThread] Failed to connect to 127.0.0.1:37017, in(checking socket for error after poll), reason: Connection refused
2018-04-30T18:37:43.175+0000 W NETWORK  [migrateThread] Unable to reach primary for set s0
2018-04-30T18:37:43.719+0000 W NETWORK  [migrateThread] Failed to connect to 127.0.0.1:37017, in(checking socket for error after poll), reason: Connection refused
2018-04-30T18:37:43.720+0000 W NETWORK  [migrateThread] Unable to reach primary for set s0
2018-04-30T18:37:44.222+0000 W NETWORK  [migrateThread] Failed to connect to 127.0.0.1:37017, in(checking socket for error after poll), reason: Connection refused
2018-04-30T18:37:44.222+0000 W NETWORK  [migrateThread] Unable to reach primary for set s0
2018-04-30T18:37:44.724+0000 W NETWORK  [migrateThread] Failed to connect to 127.0.0.1:37017, in(checking socket for error after poll), reason: Connection refused
2018-04-30T18:37:44.725+0000 W NETWORK  [migrateThread] Unable to reach primary for set s0
2018-04-30T18:37:44.725+0000 I NETWORK  [migrateThread] Cannot reach any nodes for set s0. Please check network connectivity and the status of the set. This has happened for 21 checks in a row.
2018-04-30T18:37:45.226+0000 W NETWORK  [migrateThread] Failed to connect to 127.0.0.1:37017, in(checking socket for error after poll), reason: Connection refused
2018-04-30T18:37:45.228+0000 W NETWORK  [migrateThread] Unable to reach primary for set s0
2018-04-30T18:37:45.729+0000 W NETWORK  [migrateThread] Failed to connect to 127.0.0.1:37017, in(checking socket for error after poll), reason: Connection refused
2018-04-30T18:37:45.729+0000 W NETWORK  [migrateThread] Unable to reach primary for set s0
2018-04-30T18:37:46.230+0000 W NETWORK  [migrateThread] Failed to connect to 127.0.0.1:37017, in(checking socket for error after poll), reason: Connection refused
2018-04-30T18:37:46.231+0000 W NETWORK  [migrateThread] Unable to reach primary for set s0
2018-04-30T18:37:46.731+0000 W NETWORK  [migrateThread] Failed to connect to 127.0.0.1:37017, in(checking socket for error after poll), reason: Connection refused
2018-04-30T18:37:46.731+0000 W NETWORK  [migrateThread] Unable to reach primary for set s0
2018-04-30T18:37:47.232+0000 W NETWORK  [migrateThread] Failed to connect to 127.0.0.1:37017, in(checking socket for error after poll), reason: Connection refused
2018-04-30T18:37:47.232+0000 W NETWORK  [migrateThread] Unable to reach primary for set s0
2018-04-30T18:37:47.738+0000 W NETWORK  [migrateThread] Failed to connect to 127.0.0.1:37017, in(checking socket for error after poll), reason: Connection refused
2018-04-30T18:37:47.739+0000 W NETWORK  [migrateThread] Unable to reach primary for set s0
2018-04-30T18:37:48.243+0000 W NETWORK  [migrateThread] Failed to connect to 127.0.0.1:37017, in(checking socket for error after poll), reason: Connection refused
2018-04-30T18:37:48.244+0000 W NETWORK  [migrateThread] Unable to reach primary for set s0
2018-04-30T18:37:48.746+0000 W NETWORK  [migrateThread] Failed to connect to 127.0.0.1:37017, in(checking socket for error after poll), reason: Connection refused
2018-04-30T18:37:48.746+0000 W NETWORK  [migrateThread] Unable to reach primary for set s0
2018-04-30T18:37:49.246+0000 W NETWORK  [migrateThread] Failed to connect to 127.0.0.1:37017, in(checking socket for error after poll), reason: Connection refused
2018-04-30T18:37:49.247+0000 W NETWORK  [migrateThread] Unable to reach primary for set s0
2018-04-30T18:37:49.747+0000 W NETWORK  [migrateThread] Failed to connect to 127.0.0.1:37017, in(checking socket for error after poll), reason: Connection refused
2018-04-30T18:37:49.747+0000 W NETWORK  [migrateThread] Unable to reach primary for set s0
2018-04-30T18:37:49.748+0000 I NETWORK  [migrateThread] Cannot reach any nodes for set s0. Please check network connectivity and the status of the set. This has happened for 31 checks in a row.
2018-04-30T18:37:49.748+0000 I NETWORK  [migrateThread] scoped connection to s0/localhost:37017 not being returned to the pool
2018-04-30T18:37:49.748+0000 I SHARDING [migrateThread] about to log metadata event into changelog: { _id: "tm351-18J-test-student-2018-04-30T18:37:49.748+0000-5ae7627db3f9f8ea6914d6d9", server: "tm351-18J-test-student", clientAddr: "", time: new Date(1525113469748), what: "moveChunk.to", ns: "accidents.accidents", details: { min: { Accident_Index: "200901RY10442" }, max: { Accident_Index: "200905AA31857" }, step 1 of 6: 4, step 2 of 6: 4, step 3 of 6: 29759, note: "aborted" } }
2018-04-30T18:37:49.753+0000 I SHARDING [migrateThread] migrate failed: FailedToSatisfyReadPreference: Could not find host matching read preference { mode: "primary", tags: [ {} ] } for set s0
2018-04-30T18:37:49.753+0000 I SHARDING [migrateThread] Abandoning in-migration of accidents.accidents range [{ Accident_Index: "200901RY10442" }, { Accident_Index: "200905AA31857" }); scheduling deletion of any documents already copied
2018-04-30T18:37:51.936+0000 I NETWORK  [listener] connection accepted from 127.0.0.1:55500 #11 (8 connections now open)
2018-04-30T18:37:51.943+0000 I NETWORK  [conn11] received client metadata from 127.0.0.1:55500 conn11: { driver: { name: "NetworkInterfaceASIO-ShardRegistry", version: "3.6.4" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2018-04-30T18:37:51.946+0000 I SHARDING [conn11] Refreshing chunks for collection accidents.accidents based on version 4|1||5ae7620e1b1b0bfabb4ae6f5
2018-04-30T18:37:51.964+0000 I SHARDING [ConfigServerCatalogCacheLoader-1] Cache loader remotely refreshed for collection accidents.accidents from collection version 4|1||5ae7620e1b1b0bfabb4ae6f5 and found collection version 4|34||5ae7620e1b1b0bfabb4ae6f5
2018-04-30T18:37:51.967+0000 I SHARDING [ConfigServerCatalogCacheLoader-1] Cache loader found enqueued metadata from 4|1||5ae7620e1b1b0bfabb4ae6f5 to 4|34||5ae7620e1b1b0bfabb4ae6f5 and persisted metadata from 4|1||5ae7620e1b1b0bfabb4ae6f5 to 4|6||5ae7620e1b1b0bfabb4ae6f5, GTE cache version 4|1||5ae7620e1b1b0bfabb4ae6f5
2018-04-30T18:37:51.968+0000 I SHARDING [ConfigServerCatalogCacheLoader-1] Refresh for collection accidents.accidents took 22 ms and found version 4|34||5ae7620e1b1b0bfabb4ae6f5
2018-04-30T18:37:52.050+0000 I SHARDING [conn11] Updating collection metadata for accidents.accidents from collection version: 4|1||5ae7620e1b1b0bfabb4ae6f5, shard version: 3|0||5ae7620e1b1b0bfabb4ae6f5 to collection version: 4|34||5ae7620e1b1b0bfabb4ae6f5, shard version: 3|0||5ae7620e1b1b0bfabb4ae6f5
2018-04-30T18:37:52.051+0000 I COMMAND  [conn11] command admin.$cmd command: _recvChunkStart { _recvChunkStart: "accidents.accidents", sessionId: "s2_s1_5ae7627f87a7fdf46be34dc2", from: "s2/localhost:57017", fromShardName: "s2", toShardName: "s1", min: { Accident_Index: MinKey }, max: { Accident_Index: 2009030000008 }, shardKeyPattern: { Accident_Index: 1.0 }, $clusterTime: { clusterTime: Timestamp(1525113471, 6982), signature: { hash: BinData(0, 0B3C5C947ED605D186EE74FD1FAD48612916147D), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113471, 6917), t: 1 } }, $db: "admin" } numYields:0 reslen:298 locks:{ Global: { acquireCount: { r: 3, w: 1 } }, Database: { acquireCount: { r: 1, w: 1 } }, Collection: { acquireCount: { r: 1, W: 1 }, acquireWaitCount: { W: 1 }, timeAcquiringMicros: { W: 81397 } } } protocol:op_msg 105ms
2018-04-30T18:37:52.055+0000 I SHARDING [migrateThread] Starting receiving end of migration of chunk { Accident_Index: MinKey } -> { Accident_Index: 2009030000008 } for collection accidents.accidents from s2/localhost:57017 at epoch 5ae7620e1b1b0bfabb4ae6f5 with session id s2_s1_5ae7627f87a7fdf46be34dc2
2018-04-30T18:37:52.057+0000 I NETWORK  [migrateThread] Successfully connected to s2/localhost:57017 (1 connections now open to s2/localhost:57017 with a 0 second timeout)
2018-04-30T18:37:52.135+0000 I SHARDING [migrateThread] Scheduling deletion of any documents in accidents.accidents range [{ Accident_Index: MinKey }, { Accident_Index: 2009030000008 }) before migrating in a chunk covering the range
2018-04-30T18:37:53.053+0000 I COMMAND  [conn11] command admin.$cmd command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s2_s1_5ae7627f87a7fdf46be34dc2", $clusterTime: { clusterTime: Timestamp(1525113472, 640), signature: { hash: BinData(0, 7DD2AD27E99643F0C8EFBA2AED28B3D56C2B2B13), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113471, 6917), t: 1 } }, $db: "admin" } numYields:0 reslen:615 locks:{} protocol:op_msg 999ms
2018-04-30T18:37:54.054+0000 I COMMAND  [conn11] command admin.$cmd command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s2_s1_5ae7627f87a7fdf46be34dc2", $clusterTime: { clusterTime: Timestamp(1525113473, 320), signature: { hash: BinData(0, D9BA797C0EA28E0BA305BAF6CBBE12574798051B), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113471, 6917), t: 1 } }, $db: "admin" } numYields:0 reslen:615 locks:{} protocol:op_msg 1000ms
2018-04-30T18:37:55.055+0000 I COMMAND  [conn11] command admin.$cmd command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s2_s1_5ae7627f87a7fdf46be34dc2", $clusterTime: { clusterTime: Timestamp(1525113474, 24), signature: { hash: BinData(0, 0CCE694CA0ECA04D6FA8D56DD4B5DDD81596331F), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113471, 6917), t: 1 } }, $db: "admin" } numYields:0 reslen:615 locks:{} protocol:op_msg 1000ms
2018-04-30T18:37:56.056+0000 I COMMAND  [conn11] command admin.$cmd command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s2_s1_5ae7627f87a7fdf46be34dc2", $clusterTime: { clusterTime: Timestamp(1525113475, 832), signature: { hash: BinData(0, 3EA0362456F43D3364D706AE80C2C4F4A5597FE1), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113471, 6917), t: 1 } }, $db: "admin" } numYields:0 reslen:615 locks:{} protocol:op_msg 999ms
2018-04-30T18:37:57.057+0000 I COMMAND  [conn11] command admin.$cmd command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s2_s1_5ae7627f87a7fdf46be34dc2", $clusterTime: { clusterTime: Timestamp(1525113476, 488), signature: { hash: BinData(0, 25D609084FB3A8508EAA555074494AE7F127758D), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113475, 1873), t: 1 } }, $db: "admin" } numYields:0 reslen:615 locks:{} protocol:op_msg 1000ms
2018-04-30T18:37:58.058+0000 I COMMAND  [conn11] command admin.$cmd command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s2_s1_5ae7627f87a7fdf46be34dc2", $clusterTime: { clusterTime: Timestamp(1525113477, 360), signature: { hash: BinData(0, 2CA5BF68B9A59EDCBC69381594E9E2D6818516F7), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113475, 1873), t: 1 } }, $db: "admin" } numYields:0 reslen:615 locks:{} protocol:op_msg 999ms
2018-04-30T18:37:59.059+0000 I COMMAND  [conn11] command admin.$cmd command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s2_s1_5ae7627f87a7fdf46be34dc2", $clusterTime: { clusterTime: Timestamp(1525113478, 64), signature: { hash: BinData(0, 459A8D2BCDEE49D1AFF49BE0BEF804E5A205DF61), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113475, 1873), t: 1 } }, $db: "admin" } numYields:0 reslen:615 locks:{} protocol:op_msg 1000ms
2018-04-30T18:37:59.486+0000 I SHARDING [Collection Range Deleter] No documents remain to delete in accidents.accidents range [{ Accident_Index: "200901RY10442" }, { Accident_Index: "200905AA31857" })
2018-04-30T18:37:59.486+0000 I SHARDING [Collection Range Deleter] Waiting for majority replication of local deletions in accidents.accidents range [{ Accident_Index: "200901RY10442" }, { Accident_Index: "200905AA31857" })
2018-04-30T18:37:59.487+0000 I SHARDING [Collection Range Deleter] Finished deleting documents in accidents.accidents range [{ Accident_Index: "200901RY10442" }, { Accident_Index: "200905AA31857" })
2018-04-30T18:37:59.487+0000 I SHARDING [Collection Range Deleter] No documents remain to delete in accidents.accidents range [{ Accident_Index: MinKey }, { Accident_Index: 2009030000008 })
2018-04-30T18:37:59.487+0000 I SHARDING [Collection Range Deleter] Waiting for majority replication of local deletions in accidents.accidents range [{ Accident_Index: MinKey }, { Accident_Index: 2009030000008 })
2018-04-30T18:37:59.488+0000 I SHARDING [Collection Range Deleter] Finished deleting documents in accidents.accidents range [{ Accident_Index: MinKey }, { Accident_Index: 2009030000008 })
2018-04-30T18:37:59.488+0000 I SHARDING [migrateThread] Finished deleting accidents.accidents range [{ Accident_Index: MinKey }, { Accident_Index: 2009030000008 })
2018-04-30T18:37:59.491+0000 I SHARDING [migrateThread] Waiting for replication to catch up before entering critical section
2018-04-30T18:37:59.491+0000 I SHARDING [migrateThread] migrate commit succeeded flushing to secondaries for 'accidents.accidents' { Accident_Index: MinKey } -> { Accident_Index: 2009030000008 }
2018-04-30T18:37:59.492+0000 I COMMAND  [conn11] command admin.$cmd command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s2_s1_5ae7627f87a7fdf46be34dc2", $clusterTime: { clusterTime: Timestamp(1525113479, 320), signature: { hash: BinData(0, 5247338A3FF525562DC2A18222092364B5F2D2F5), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113475, 1873), t: 1 } }, $db: "admin" } numYields:0 reslen:616 locks:{} protocol:op_msg 431ms
2018-04-30T18:37:59.492+0000 I ASIO     [NetworkInterfaceASIO-ShardRegistry-0] Connecting to localhost:57017
2018-04-30T18:37:59.500+0000 I ASIO     [NetworkInterfaceASIO-ShardRegistry-0] Successfully connected to localhost:57017, took 8ms (1 connections now open to localhost:57017)
2018-04-30T18:37:59.502+0000 I SHARDING [migrateThread] migrate commit succeeded flushing to secondaries for 'accidents.accidents' { Accident_Index: MinKey } -> { Accident_Index: 2009030000008 }
2018-04-30T18:37:59.703+0000 I SHARDING [migrateThread] about to log metadata event into changelog: { _id: "tm351-18J-test-student-2018-04-30T18:37:59.703+0000-5ae76287b3f9f8ea6914d722", server: "tm351-18J-test-student", clientAddr: "", time: new Date(1525113479703), what: "moveChunk.to", ns: "accidents.accidents", details: { min: { Accident_Index: MinKey }, max: { Accident_Index: 2009030000008 }, step 1 of 6: 79, step 2 of 6: 7352, step 3 of 6: 3, step 4 of 6: 0, step 5 of 6: 11, step 6 of 6: 200, note: "success" } }
2018-04-30T18:37:59.767+0000 I COMMAND  [conn11] command admin.$cmd command: _recvChunkCommit { _recvChunkCommit: "accidents.accidents", waitForSteadyOrDone: false, sessionId: "s2_s1_5ae7627f87a7fdf46be34dc2", $clusterTime: { clusterTime: Timestamp(1525113479, 4962), signature: { hash: BinData(0, 5247338A3FF525562DC2A18222092364B5F2D2F5), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113475, 1873), t: 1 } }, $db: "admin" } numYields:0 reslen:559 locks:{} protocol:op_msg 268ms
2018-04-30T18:37:59.781+0000 I SHARDING [conn11] Refreshing chunks for collection accidents.accidents based on version 4|34||5ae7620e1b1b0bfabb4ae6f5
2018-04-30T18:37:59.784+0000 I SHARDING [ConfigServerCatalogCacheLoader-1] Cache loader remotely refreshed for collection accidents.accidents from collection version 4|34||5ae7620e1b1b0bfabb4ae6f5 and found collection version 5|1||5ae7620e1b1b0bfabb4ae6f5
2018-04-30T18:37:59.785+0000 I SHARDING [ConfigServerCatalogCacheLoader-1] Cache loader found enqueued metadata from 4|34||5ae7620e1b1b0bfabb4ae6f5 to 5|1||5ae7620e1b1b0bfabb4ae6f5 and persisted metadata from 4|34||5ae7620e1b1b0bfabb4ae6f5 to 4|34||5ae7620e1b1b0bfabb4ae6f5, GTE cache version 4|34||5ae7620e1b1b0bfabb4ae6f5
2018-04-30T18:37:59.787+0000 I SHARDING [ConfigServerCatalogCacheLoader-1] Refresh for collection accidents.accidents took 5 ms and found version 5|1||5ae7620e1b1b0bfabb4ae6f5
2018-04-30T18:37:59.787+0000 I SHARDING [conn11] Updating collection metadata for accidents.accidents from collection version: 4|34||5ae7620e1b1b0bfabb4ae6f5, shard version: 3|0||5ae7620e1b1b0bfabb4ae6f5 to collection version: 5|1||5ae7620e1b1b0bfabb4ae6f5, shard version: 5|0||5ae7620e1b1b0bfabb4ae6f5
2018-04-30T18:38:01.543+0000 W NETWORK  [ReplicaSetMonitor-TaskExecutor-0] Failed to connect to 127.0.0.1:37017, in(checking socket for error after poll), reason: Connection refused
2018-04-30T18:38:01.543+0000 W NETWORK  [ReplicaSetMonitor-TaskExecutor-0] Unable to reach primary for set s0
2018-04-30T18:38:21.728+0000 I SHARDING [conn11] Refreshing chunks for collection accidents.accidents based on version 5|1||5ae7620e1b1b0bfabb4ae6f5
2018-04-30T18:38:21.730+0000 I SHARDING [ConfigServerCatalogCacheLoader-1] Cache loader remotely refreshed for collection accidents.accidents from collection version 5|1||5ae7620e1b1b0bfabb4ae6f5 and found collection version 5|10||5ae7620e1b1b0bfabb4ae6f5
2018-04-30T18:38:21.732+0000 I SHARDING [ConfigServerCatalogCacheLoader-1] Cache loader found enqueued metadata from 5|1||5ae7620e1b1b0bfabb4ae6f5 to 5|10||5ae7620e1b1b0bfabb4ae6f5 and persisted metadata from 5|1||5ae7620e1b1b0bfabb4ae6f5 to 5|10||5ae7620e1b1b0bfabb4ae6f5, GTE cache version 5|1||5ae7620e1b1b0bfabb4ae6f5
2018-04-30T18:38:21.733+0000 I SHARDING [ConfigServerCatalogCacheLoader-1] Refresh for collection accidents.accidents took 4 ms and found version 5|10||5ae7620e1b1b0bfabb4ae6f5
2018-04-30T18:38:21.734+0000 I SHARDING [conn11] Updating collection metadata for accidents.accidents from collection version: 5|1||5ae7620e1b1b0bfabb4ae6f5, shard version: 5|0||5ae7620e1b1b0bfabb4ae6f5 to collection version: 5|10||5ae7620e1b1b0bfabb4ae6f5, shard version: 5|0||5ae7620e1b1b0bfabb4ae6f5
2018-04-30T18:38:21.734+0000 I SHARDING [migrateThread] Starting receiving end of migration of chunk { Accident_Index: "201242I193506" } -> { Accident_Index: MaxKey } for collection accidents.accidents from s2/localhost:57017 at epoch 5ae7620e1b1b0bfabb4ae6f5 with session id s2_s1_5ae7629d87a7fdf46be34eb6
2018-04-30T18:38:21.735+0000 I SHARDING [migrateThread] Scheduling deletion of any documents in accidents.accidents range [{ Accident_Index: "201242I193506" }, { Accident_Index: MaxKey }) before migrating in a chunk covering the range
2018-04-30T18:38:21.735+0000 I SHARDING [Collection Range Deleter] No documents remain to delete in accidents.accidents range [{ Accident_Index: "201242I193506" }, { Accident_Index: MaxKey })
2018-04-30T18:38:21.736+0000 I SHARDING [Collection Range Deleter] Waiting for majority replication of local deletions in accidents.accidents range [{ Accident_Index: "201242I193506" }, { Accident_Index: MaxKey })
2018-04-30T18:38:21.736+0000 I SHARDING [Collection Range Deleter] Finished deleting documents in accidents.accidents range [{ Accident_Index: "201242I193506" }, { Accident_Index: MaxKey })
2018-04-30T18:38:21.736+0000 I SHARDING [migrateThread] Finished deleting accidents.accidents range [{ Accident_Index: "201242I193506" }, { Accident_Index: MaxKey })
2018-04-30T18:38:22.734+0000 I COMMAND  [conn11] command admin.$cmd command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s2_s1_5ae7629d87a7fdf46be34eb6", $clusterTime: { clusterTime: Timestamp(1525113501, 22), signature: { hash: BinData(0, 483C00836AB24AFD91557A2A58574DDAA2C7DBC0), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113501, 4), t: 1 } }, $db: "admin" } numYields:0 reslen:625 locks:{} protocol:op_msg 999ms
2018-04-30T18:38:23.735+0000 I COMMAND  [conn11] command admin.$cmd command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s2_s1_5ae7629d87a7fdf46be34eb6", $clusterTime: { clusterTime: Timestamp(1525113502, 1669), signature: { hash: BinData(0, 9C3372CD1A8DF8922EB28BF4004700793E44EA49), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113501, 4), t: 1 } }, $db: "admin" } numYields:0 reslen:625 locks:{} protocol:op_msg 999ms
2018-04-30T18:38:24.735+0000 I COMMAND  [conn11] command admin.$cmd command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s2_s1_5ae7629d87a7fdf46be34eb6", $clusterTime: { clusterTime: Timestamp(1525113503, 2438), signature: { hash: BinData(0, AF593688295C3D5D0B47D3F2EBCACF5D2C215E21), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113501, 4), t: 1 } }, $db: "admin" } numYields:0 reslen:625 locks:{} protocol:op_msg 999ms
2018-04-30T18:38:25.736+0000 I COMMAND  [conn11] command admin.$cmd command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s2_s1_5ae7629d87a7fdf46be34eb6", $clusterTime: { clusterTime: Timestamp(1525113504, 2689), signature: { hash: BinData(0, 7703A3252457269A53A4659A27766AEA5897611E), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113501, 4), t: 1 } }, $db: "admin" } numYields:0 reslen:625 locks:{} protocol:op_msg 999ms
2018-04-30T18:38:26.737+0000 I COMMAND  [conn11] command admin.$cmd command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s2_s1_5ae7629d87a7fdf46be34eb6", $clusterTime: { clusterTime: Timestamp(1525113505, 2773), signature: { hash: BinData(0, 4FD30FEA6C9040596AC15D4FCFE629D14CF09EA1), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113501, 4), t: 1 } }, $db: "admin" } numYields:0 reslen:625 locks:{} protocol:op_msg 999ms
2018-04-30T18:38:27.738+0000 I COMMAND  [conn11] command admin.$cmd command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s2_s1_5ae7629d87a7fdf46be34eb6", $clusterTime: { clusterTime: Timestamp(1525113506, 2726), signature: { hash: BinData(0, CC9299D119F80137AA09564ACC36A0A88D673531), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113501, 4), t: 1 } }, $db: "admin" } numYields:0 reslen:625 locks:{} protocol:op_msg 999ms
2018-04-30T18:38:28.739+0000 I COMMAND  [conn11] command admin.$cmd command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s2_s1_5ae7629d87a7fdf46be34eb6", $clusterTime: { clusterTime: Timestamp(1525113507, 2824), signature: { hash: BinData(0, C7561F92A85523EB8E8C8E08E6EE681F00394F73), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113501, 4), t: 1 } }, $db: "admin" } numYields:0 reslen:625 locks:{} protocol:op_msg 999ms
2018-04-30T18:38:29.109+0000 I SHARDING [migrateThread] Waiting for replication to catch up before entering critical section
2018-04-30T18:38:29.110+0000 I SHARDING [migrateThread] migrate commit succeeded flushing to secondaries for 'accidents.accidents' { Accident_Index: "201242I193506" } -> { Accident_Index: MaxKey }
2018-04-30T18:38:29.110+0000 I COMMAND  [conn11] command admin.$cmd command: _recvChunkStatus { _recvChunkStatus: "accidents.accidents", waitForSteadyOrDone: true, sessionId: "s2_s1_5ae7629d87a7fdf46be34eb6", $clusterTime: { clusterTime: Timestamp(1525113508, 2433), signature: { hash: BinData(0, 6E2B73D43A58E849867356BDFBF6AF52A2A6D7FA), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113501, 4), t: 1 } }, $db: "admin" } numYields:0 reslen:626 locks:{} protocol:op_msg 368ms
2018-04-30T18:38:29.152+0000 I SHARDING [migrateThread] migrate commit succeeded flushing to secondaries for 'accidents.accidents' { Accident_Index: "201242I193506" } -> { Accident_Index: MaxKey }
2018-04-30T18:38:29.505+0000 I SHARDING [migrateThread] about to log metadata event into changelog: { _id: "tm351-18J-test-student-2018-04-30T18:38:29.502+0000-5ae762a5b3f9f8ea6914d760", server: "tm351-18J-test-student", clientAddr: "", time: new Date(1525113509502), what: "moveChunk.to", ns: "accidents.accidents", details: { min: { Accident_Index: "201242I193506" }, max: { Accident_Index: MaxKey }, step 1 of 6: 0, step 2 of 6: 1, step 3 of 6: 7372, step 4 of 6: 0, step 5 of 6: 43, step 6 of 6: 347, note: "success" } }
2018-04-30T18:38:29.512+0000 I COMMAND  [conn11] command admin.$cmd command: _recvChunkCommit { _recvChunkCommit: "accidents.accidents", waitForSteadyOrDone: false, sessionId: "s2_s1_5ae7629d87a7fdf46be34eb6", $clusterTime: { clusterTime: Timestamp(1525113509, 311), signature: { hash: BinData(0, 1E9A41069C1E2F0D37B0CA3968E52BC83C99E4F4), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113501, 4), t: 1 } }, $db: "admin" } numYields:0 reslen:569 locks:{} protocol:op_msg 369ms
2018-04-30T18:38:29.543+0000 I SHARDING [conn11] Refreshing chunks for collection accidents.accidents based on version 5|10||5ae7620e1b1b0bfabb4ae6f5
2018-04-30T18:38:29.548+0000 I SHARDING [ConfigServerCatalogCacheLoader-1] Cache loader remotely refreshed for collection accidents.accidents from collection version 5|10||5ae7620e1b1b0bfabb4ae6f5 and found collection version 6|1||5ae7620e1b1b0bfabb4ae6f5
2018-04-30T18:38:29.548+0000 I SHARDING [ConfigServerCatalogCacheLoader-1] Cache loader found enqueued metadata from 6|0||5ae7620e1b1b0bfabb4ae6f5 to 6|1||5ae7620e1b1b0bfabb4ae6f5 and persisted metadata from 5|10||5ae7620e1b1b0bfabb4ae6f5 to 5|10||5ae7620e1b1b0bfabb4ae6f5, GTE cache version 5|10||5ae7620e1b1b0bfabb4ae6f5
2018-04-30T18:38:29.549+0000 I SHARDING [ConfigServerCatalogCacheLoader-1] Refresh for collection accidents.accidents took 5 ms and found version 6|1||5ae7620e1b1b0bfabb4ae6f5
2018-04-30T18:38:29.549+0000 I SHARDING [conn11] Updating collection metadata for accidents.accidents from collection version: 5|10||5ae7620e1b1b0bfabb4ae6f5, shard version: 5|0||5ae7620e1b1b0bfabb4ae6f5 to collection version: 6|1||5ae7620e1b1b0bfabb4ae6f5, shard version: 6|0||5ae7620e1b1b0bfabb4ae6f5
2018-04-30T18:38:31.597+0000 W NETWORK  [ReplicaSetMonitor-TaskExecutor-0] Failed to connect to 127.0.0.1:37017, in(checking socket for error after poll), reason: Connection refused
2018-04-30T18:38:31.598+0000 W NETWORK  [ReplicaSetMonitor-TaskExecutor-0] Unable to reach primary for set s0
2018-04-30T18:38:49.186+0000 I NETWORK  [listener] connection accepted from 127.0.0.1:55912 #12 (9 connections now open)
2018-04-30T18:38:49.189+0000 I NETWORK  [conn12] received client metadata from 127.0.0.1:55912 conn12: { driver: { name: "NetworkInterfaceASIO-TaskExecutorPool-0", version: "3.6.4" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2018-04-30T18:38:49.200+0000 I INDEX    [conn12] build index on: accidents.accidents properties: { v: 2, key: { loc: "2dsphere" }, name: "loc_2dsphere", ns: "accidents.accidents", 2dsphereIndexVersion: 3 }
2018-04-30T18:38:49.200+0000 I INDEX    [conn12] 	 building index using bulk method; build may temporarily use up to 166 megabytes of RAM
2018-04-30T18:38:49.205+0000 I INDEX    [conn12] build index on: accidents.accidents properties: { v: 2, key: { Datetime: 1 }, name: "Datetime_1", ns: "accidents.accidents" }
2018-04-30T18:38:49.205+0000 I INDEX    [conn12] 	 building index using bulk method; build may temporarily use up to 166 megabytes of RAM
2018-04-30T18:38:49.210+0000 I INDEX    [conn12] build index on: accidents.accidents properties: { v: 2, key: { Speed_limit: 1 }, name: "Speed_limit_1", ns: "accidents.accidents" }
2018-04-30T18:38:49.211+0000 I INDEX    [conn12] 	 building index using bulk method; build may temporarily use up to 166 megabytes of RAM
2018-04-30T18:38:50.700+0000 I INDEX    [conn12] build index done.  scanned 38437 total records. 1 secs
2018-04-30T18:38:50.716+0000 I COMMAND  [conn12] command accidents.$cmd command: createIndexes { createIndexes: "accidents", indexes: [ { name: "Accident_Index_1", ns: "accidents.accidents", key: { Accident_Index: 1.0 } }, { name: "loc_2dsphere", ns: "accidents.accidents", 2dsphereIndexVersion: 3, key: { loc: "2dsphere" } }, { name: "Datetime_1", ns: "accidents.accidents", key: { Datetime: 1 } }, { name: "Speed_limit_1", ns: "accidents.accidents", key: { Speed_limit: 1 } } ], allowImplicitCollectionCreation: false, $clusterTime: { clusterTime: Timestamp(1525113521, 1), signature: { hash: BinData(0, EFE87840E27F763178F1945AB8D7A42FD5E23BAC), keyId: 6550311832093982739 } }, $configServerState: { opTime: { ts: Timestamp(1525113521, 1), t: 1 } }, $db: "accidents" } numYields:0 reslen:395 locks:{ Global: { acquireCount: { r: 4, w: 4 } }, Database: { acquireCount: { w: 3, W: 1 } }, Collection: { acquireCount: { w: 1 } }, oplog: { acquireCount: { w: 3 } } } protocol:op_msg 1522ms
2018-04-30T18:38:57.094+0000 I CONTROL  [signalProcessingThread] got signal 15 (Terminated), will terminate after current cmd ends
2018-04-30T18:38:57.097+0000 I NETWORK  [signalProcessingThread] shutdown: going to close listening sockets...
2018-04-30T18:38:57.098+0000 I NETWORK  [signalProcessingThread] removing socket file: /tmp/mongodb-47017.sock
2018-04-30T18:38:57.105+0000 I REPL     [signalProcessingThread] shutting down replication subsystems
2018-04-30T18:38:57.106+0000 I REPL     [signalProcessingThread] Stopping replication reporter thread
2018-04-30T18:38:57.107+0000 I REPL     [signalProcessingThread] Stopping replication fetcher thread
2018-04-30T18:38:57.110+0000 I REPL     [signalProcessingThread] Stopping replication applier thread
2018-04-30T18:38:57.120+0000 I NETWORK  [conn12] end connection 127.0.0.1:55912 (8 connections now open)
2018-04-30T18:38:57.120+0000 I NETWORK  [conn4] end connection 127.0.0.1:55096 (7 connections now open)
2018-04-30T18:38:57.120+0000 I NETWORK  [conn9] end connection 127.0.0.1:55248 (6 connections now open)
2018-04-30T18:38:57.506+0000 I NETWORK  [conn5] end connection 127.0.0.1:55120 (5 connections now open)
2018-04-30T18:38:57.506+0000 I NETWORK  [conn11] end connection 127.0.0.1:55500 (4 connections now open)
2018-04-30T18:38:57.519+0000 I REPL     [signalProcessingThread] Stopping replication storage threads
2018-04-30T18:38:57.528+0000 W SHARDING [signalProcessingThread] error encountered while cleaning up distributed ping entry for tm351-18J-test-student:47017:1525113358:5111203876141935344 :: caused by :: ShutdownInProgress: Shutdown in progress
2018-04-30T18:38:57.529+0000 W SHARDING [signalProcessingThread] cant reload ShardRegistry  :: caused by :: CallbackCanceled: Callback canceled
2018-04-30T18:38:57.530+0000 I FTDC     [signalProcessingThread] Shutting down full-time diagnostic data capture
2018-04-30T18:38:57.535+0000 I STORAGE  [WTOplogJournalThread] oplog journal thread loop shutting down
2018-04-30T18:38:57.536+0000 I STORAGE  [signalProcessingThread] WiredTigerKVEngine shutting down
2018-04-30T18:38:57.954+0000 I STORAGE  [signalProcessingThread] shutdown: removing fs lock...
2018-04-30T18:38:57.954+0000 I CONTROL  [signalProcessingThread] now exiting
2018-04-30T18:38:57.954+0000 I CONTROL  [signalProcessingThread] shutting down with code:0
